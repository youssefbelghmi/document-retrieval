{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c84ef613-3ed6-46fd-80ea-dd79ae3de5d3",
   "metadata": {},
   "source": [
    "# Computations\n",
    "In this notebook, we will compute the IDF dictionaries and TF-IDF sparse matrices / BM25 sparse matrices for each language in our multilingual corpus. These computations will allow us to represent the importance of terms in documents across languages. The final result will be useful in preparing data for efficient document retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aabbe8f-7ef5-4078-8669-d38abf9868fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e682c4f4-1630-4862-bdbe-21a4f7fe0119",
   "metadata": {},
   "source": [
    "Let's import the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bbcc7c-a791-423d-89eb-e5b1eb6d331d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os                      # For file system operations (saving/loading files)\n",
    "import numpy as np             # For numerical operations\n",
    "import pandas as pd            # For working with DataFrames and CSV files\n",
    "import scipy.sparse as sp      # For creating and saving sparse TF-IDF matrices (csr_matrix, save_npz)\n",
    "from math import log           # For calculating logarithms (used in IDF calculation)\n",
    "from tqdm import tqdm          # For displaying progress bars\n",
    "from collections import defaultdict, Counter  # For counting document frequencies and other counting needs\n",
    "from scipy.sparse import csr_matrix  # For creating sparse matrices in Compressed Sparse Row (CSR) format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3f8ef5-feeb-4e0b-941a-3209ef91b451",
   "metadata": {},
   "source": [
    "First, we need to load the preprocessed corpus for each language to create the corresponding IDF dictionary and then the sparse TF-IDF matrices required for the rest of the implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc25a2e-b726-45d3-9f3e-01cbf7118772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading preprocessed CSVs for each language\n",
    "corpus_files = {\n",
    "    'en': 'Data/corpus_en_processed.csv',\n",
    "    'fr': 'Data/corpus_fr_processed.csv',\n",
    "    'de': 'Data/corpus_de_processed.csv',\n",
    "    'es': 'Data/corpus_es_processed.csv',\n",
    "    'it': 'Data/corpus_it_processed.csv',\n",
    "    'ar': 'Data/corpus_ar_processed.csv',\n",
    "    'ko': 'Data/corpus_ko_processed.csv'\n",
    "}\n",
    "\n",
    "# Dictionary to store the loaded data for each language\n",
    "corpus_data = {}\n",
    "\n",
    "# Loop through the dictionary to load the CSV files for each language\n",
    "for lang, filepath in corpus_files.items():\n",
    "    # Load the CSV file into a pandas DataFrame and store it in the corpus_data dictionary\n",
    "    corpus_data[lang] = pd.read_csv(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5c1c38-db28-403a-bce0-d9746c234eb6",
   "metadata": {},
   "source": [
    "Let us implement the function that will determine the relative importance of each term in the corpus, which is essential for many natural language processing tasks, especially when combined with term frequency (TF) to form the TF-IDF matrix used for document retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32172ff4-ec4e-49b4-b88f-fc3f63a65fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_idf_dictionary(df, lang):\n",
    "    # Total number of documents\n",
    "    total_docs = len(df)\n",
    "    \n",
    "    # Dictionary to store document frequency of each term\n",
    "    df_dict = defaultdict(int)\n",
    "    \n",
    "    # Iterate over each row with a progress bar and calculate document frequencies\n",
    "    for _, row in tqdm(df.iterrows(), total=total_docs, desc=f\"Processing Documents for {lang}\"):\n",
    "        text = row['text']  # Assume text is already pre-processed\n",
    "        \n",
    "        # Split the pre-processed text into tokens (words)\n",
    "        tokens = text.split()  # Assuming space-separated tokens\n",
    "        \n",
    "        # Get unique terms in the document to avoid counting duplicates\n",
    "        unique_terms = set(tokens)\n",
    "        \n",
    "        # Update document frequency for each term\n",
    "        for term in unique_terms:\n",
    "            df_dict[term] += 1\n",
    "    \n",
    "    # Compute IDF for each term\n",
    "    idf_dict = {term: log(total_docs / (df_value + 1)) for term, df_value in df_dict.items()}  # Add 1 to avoid division by zero\n",
    "    \n",
    "    print(f\"IDF dictionary for {lang} created.\")\n",
    "    \n",
    "    return idf_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e031aef7-a33e-4b50-8702-c1a92f93b692",
   "metadata": {},
   "source": [
    "Each of the following cell will create the IDF dictionary for one specific language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887eb13c-936c-4d5d-b4e8-a6018f34ad15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create IDF dictionary for English\n",
    "lang = 'en'\n",
    "corpus_en = corpus_data[lang] \n",
    "idf_dict_en = create_idf_dictionary(corpus_en, lang)\n",
    "\n",
    "# Save the dictionary\n",
    "pd.to_pickle(idf_dict_en, 'Data/idf_dict_en.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfa9bc8-9adc-4b41-badb-317dd88114b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create IDF dictionary for French\n",
    "lang = 'fr'\n",
    "corpus_fr = corpus_data[lang]\n",
    "idf_dict_fr = create_idf_dictionary(corpus_fr, lang)\n",
    "\n",
    "# Save the dictionary\n",
    "pd.to_pickle(idf_dict_fr, 'Data/idf_dict_fr.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c1845d-bb50-4e08-9cce-c93d9d97e743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create IDF dictionary for German\n",
    "lang = 'de'\n",
    "corpus_de = corpus_data[lang] \n",
    "idf_dict_de = create_idf_dictionary(corpus_de, lang)\n",
    "\n",
    "# Save the dictionary\n",
    "pd.to_pickle(idf_dict_de, 'Data/idf_dict_de.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d31094-db54-43a4-917c-5716c5cd3537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create IDF dictionary for Spanish\n",
    "lang = 'es'\n",
    "corpus_es = corpus_data[lang] \n",
    "idf_dict_es = create_idf_dictionary(corpus_es, lang)\n",
    "\n",
    "# Save the dictionary\n",
    "pd.to_pickle(idf_dict_es, 'Data/idf_dict_es.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b187aac-8f5b-40c5-9ef4-162437e5afca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create IDF dictionary for Italian\n",
    "lang = 'it'\n",
    "corpus_it = corpus_data[lang] \n",
    "idf_dict_it = create_idf_dictionary(corpus_it, lang)\n",
    "\n",
    "# Save the dictionary\n",
    "pd.to_pickle(idf_dict_it, 'Data/idf_dict_it.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6915e2e6-985c-44a1-accf-32b44372d2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create IDF dictionary for Arabic\n",
    "lang = 'ar'\n",
    "corpus_ar = corpus_data[lang]\n",
    "idf_dict_ar = create_idf_dictionary(corpus_ar, lang)\n",
    "\n",
    "# Save the dictionary\n",
    "pd.to_pickle(idf_dict_ar, 'Data/idf_dict_ar.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd411fb0-6b13-4caf-b1cc-d1ee8836a42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create IDF dictionary for Korean\n",
    "lang = 'ko'\n",
    "corpus_ko = corpus_data[lang] \n",
    "idf_dict_ko = create_idf_dictionary(corpus_ko, lang)\n",
    "\n",
    "# Save the dictionary\n",
    "pd.to_pickle(idf_dict_ko, 'Data/idf_dict_ko.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909b8878-be64-4471-97b2-f5503d13ab97",
   "metadata": {},
   "source": [
    "We create dictionnaries that map docids to doc lengths for each language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483150a1-c4c9-40f0-9f36-2a420b12d4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_doc_lengths(df, lang):\n",
    "    # Filter the DataFrame for the specified language\n",
    "    filtered_df = df[df['lang'] == lang]\n",
    "    \n",
    "    # Create a dictionary mapping docid to the length of the text\n",
    "    doc_length_dict = {row['docid']: len(row['text'].split()) for _, row in filtered_df.iterrows()}\n",
    "    \n",
    "    return doc_length_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c2c3da-a3d3-419b-8d43-a46c95e3953a",
   "metadata": {},
   "source": [
    "Each of the following cell will create the length dictionary for one specific language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b54dff-8012-4575-907f-a50466481f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create doclen dictionary for English\n",
    "lang = 'en'\n",
    "corpus_en = corpus_data['en']\n",
    "doc_len_dict_en = get_doc_lengths(corpus_en, lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba66239-1feb-4499-bf33-22b14a59c28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create doclen dictionary for French\n",
    "lang = 'fr'\n",
    "corpus_fr = corpus_data['fr']\n",
    "doc_len_dict_fr = get_doc_lengths(corpus_fr, lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916e0e86-7b45-4853-ac0d-62a72639a0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create doclen dictionary for German\n",
    "lang = 'de'\n",
    "corpus_de = corpus_data['de']\n",
    "doc_len_dict_de = get_doc_lengths(corpus_de, lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e076ba-4611-4cad-83d1-4638ccd4d7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create doclen dictionary for Spanish\n",
    "lang = 'es'\n",
    "corpus_es = corpus_data['es']\n",
    "doc_len_dict_es = get_doc_lengths(corpus_es, lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b32a5fd-cf40-41a8-be42-3c7fd011b099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create doclen dictionary for Italian\n",
    "lang = 'it'\n",
    "corpus_it = corpus_data['it']\n",
    "doc_len_dict_it = get_doc_lengths(corpus_it, lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987f352b-5a20-4d12-a254-5cb14894f263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create doclen dictionary for Arabic\n",
    "lang = 'ar'\n",
    "corpus_ar = corpus_data['ar']\n",
    "doc_len_dict_ar = get_doc_lengths(corpus_ar, lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fd1935-333c-4070-8f4d-110cb4b312fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create doclen dictionary for Korean\n",
    "lang = 'ko'\n",
    "corpus_ko = corpus_data['ko']\n",
    "doc_len_dict_ko = get_doc_lengths(corpus_ko, lang)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0eb532-d8ff-4654-ad71-849b050a907f",
   "metadata": {},
   "source": [
    "We computed IDF dictionaries that provide weights for each term in the corpus in order to adjust the term frequencies in each document. Thus, we can now compute TF-IDF matrices by combining the term frequencies (TFs) with these IDF weights to create a matrix that reflects the importance of terms in each document, relative to the entire corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82e5255-a19c-42ce-904d-74257e94f277",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tf_idf_sparse_matrix(df, idf_dict):\n",
    "    # Build the vocabulary (unique terms in the IDF dictionary)\n",
    "    vocabulary = sorted(idf_dict.keys())\n",
    "    term_to_index = {term: idx for idx, term in enumerate(vocabulary)}\n",
    "    \n",
    "    # Initialize lists to store sparse matrix data\n",
    "    rows = []\n",
    "    cols = []\n",
    "    data = []\n",
    "    \n",
    "    # Compute term frequency (TF) for each document and combine with IDF to get TF-IDF\n",
    "    for doc_idx, text in tqdm(enumerate(df['text']), total=len(df), desc=\"Processing Documents\"):\n",
    "        # Split the preprocessed text into tokens\n",
    "        tokens = text.split()\n",
    "        \n",
    "        # Count term frequencies in the document\n",
    "        term_counts = Counter(tokens)\n",
    "        total_terms = len(tokens)  # Total number of terms in the document\n",
    "        \n",
    "        # Create the TF-IDF values for each term in the document\n",
    "        for term, count in term_counts.items():\n",
    "            if term in term_to_index:\n",
    "                # Calculate TF-IDF: (term frequency / max term frequency) * IDF\n",
    "                tf_idf_value = (count / total_terms) * idf_dict[term]\n",
    "                \n",
    "                # Append to sparse matrix lists (row, column, data)\n",
    "                rows.append(doc_idx)\n",
    "                cols.append(term_to_index[term])\n",
    "                data.append(tf_idf_value)\n",
    "    \n",
    "    # Create the sparse matrix (Compressed Sparse Row format)\n",
    "    tf_idf_matrix = csr_matrix((data, (rows, cols)), shape=(len(df), len(vocabulary)))\n",
    "    \n",
    "    return tf_idf_matrix, vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a45559-b43f-4e85-8348-47ba6cc60b3c",
   "metadata": {},
   "source": [
    "Now we can calculate the sparse TF-IDF matrix of each language as well as the corresponding vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cc9e2e-6bbf-4600-ab79-fbaa150b4b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the TF-IDF sparse matrix for English\n",
    "tf_idf_matrix_en, tf_idf_vocabulary_en = create_tf_idf_sparse_matrix(corpus_data['en'], idf_dict_en)\n",
    "\n",
    "# Save the TF-IDF matrix and vocabulary\n",
    "sp.save_npz('Data/tf_idf_matrix_en.npz', tf_idf_matrix_en)\n",
    "pd.to_pickle(tf_idf_vocabulary_en, 'Data/tf_idf_vocabulary_en.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2f461a-a038-44db-874e-3b30f06f6560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the TF-IDF sparse matrix for French\n",
    "tf_idf_matrix_fr, tf_idf_vocabulary_fr = create_tf_idf_sparse_matrix(corpus_data['fr'], idf_dict_fr)\n",
    "\n",
    "# Save the TF-IDF matrix and vocabulary\n",
    "sp.save_npz('Data/tf_idf_matrix_fr.npz', tf_idf_matrix_fr)\n",
    "pd.to_pickle(tf_idf_vocabulary_fr, 'Data/tf_idf_vocabulary_fr.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca66a41-a4c7-4333-982b-7da72aeb594c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the TF-IDF sparse matrix for German\n",
    "tf_idf_matrix_de, tf_idf_vocabulary_de = create_tf_idf_sparse_matrix(corpus_data['de'], idf_dict_de)\n",
    "\n",
    "# Save the TF-IDF matrix and vocabulary\n",
    "sp.save_npz('Data/tf_idf_matrix_de.npz', tf_idf_matrix_de)\n",
    "pd.to_pickle(tf_idf_vocabulary_de, 'Data/tf_idf_vocabulary_de.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723659a3-f21a-4419-9ce9-7d399cf7bb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the TF-IDF sparse matrix for Spanish\n",
    "tf_idf_matrix_es, tf_idf_vocabulary_es = create_tf_idf_sparse_matrix(corpus_data['es'], idf_dict_es)\n",
    "\n",
    "# Save the TF-IDF matrix and vocabulary\n",
    "sp.save_npz('Data/tf_idf_matrix_es.npz', tf_idf_matrix_es)\n",
    "pd.to_pickle(tf_idf_vocabulary_es, 'Data/tf_idf_vocabulary_es.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de6edb0-59d0-44b2-bfac-8ad1ef29da01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the TF-IDF sparse matrix for Italian\n",
    "tf_idf_matrix_it, tf_idf_vocabulary_it = create_tf_idf_sparse_matrix(corpus_data['it'], idf_dict_it)\n",
    "\n",
    "# Save the TF-IDF matrix and vocabulary\n",
    "sp.save_npz('Data/tf_idf_matrix_it.npz', tf_idf_matrix_it)\n",
    "pd.to_pickle(tf_idf_vocabulary_it, 'Data/tf_idf_vocabulary_it.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54568d5e-8284-41fd-9af7-5c9c5d7d6d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the TF-IDF sparse matrix for Arabic\n",
    "tf_idf_matrix_ar, tf_idf_vocabulary_ar = create_tf_idf_sparse_matrix(corpus_data['ar'], idf_dict_ar)\n",
    "\n",
    "# Save the TF-IDF matrix and vocabulary\n",
    "sp.save_npz('Data/tf_idf_matrix_ar.npz', tf_idf_matrix_ar)\n",
    "pd.to_pickle(tf_idf_vocabulary_ar, 'Data/tf_idf_vocabulary_ar.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130c8d3e-e103-467a-8aa1-5d2169d94c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the TF-IDF sparse matrix for Korean\n",
    "tf_idf_matrix_ko, tf_idf_vocabulary_ko = create_tf_idf_sparse_matrix(corpus_data['ko'], idf_dict_ko)\n",
    "\n",
    "# Save the TF-IDF matrix and vocabulary\n",
    "sp.save_npz('Data/tf_idf_matrix_ko.npz', tf_idf_matrix_ko)\n",
    "pd.to_pickle(tf_idf_vocabulary_ko, 'Data/tf_idf_vocabulary_ko.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1a0b9e-2f25-4f57-9abd-be885f982bb9",
   "metadata": {},
   "source": [
    "\n",
    "We created a sparse BM25 matrix to capture term importance across documents, adjusting term frequencies (TFs) by combining them with inverse document frequencies (IDFs) and length normalization factors. This matrix allows us to weight terms in each document relative to the corpus, enhancing retrieval accuracy by emphasizing terms that are informative within a document and rare in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59535b54-8670-457e-b245-6ea352b25bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bm25_sparse_matrix(df, doc_length_dict, idf_dict, b=0.75, k1=1.2, avgdl=200):\n",
    "    # Build the vocabulary (unique terms in the IDF dictionary)\n",
    "    vocabulary = sorted(idf_dict.keys())\n",
    "    term_to_index = {term: idx for idx, term in enumerate(vocabulary)}\n",
    "    \n",
    "    # Initialize lists to store sparse matrix data\n",
    "    rows = []\n",
    "    cols = []\n",
    "    data = []\n",
    "    \n",
    "    # Loop through each document\n",
    "    for doc_idx, (docid, text) in tqdm(enumerate(zip(df['docid'], df['text'])), total=len(df), desc=\"Processing Documents\"):\n",
    "        # Split the preprocessed text into tokens\n",
    "        tokens = text.split()\n",
    "        \n",
    "        # Count term frequencies in the document\n",
    "        term_counts = Counter(tokens)\n",
    "        \n",
    "        # Retrieve document length\n",
    "        doc_length = doc_length_dict.get(docid, 0)\n",
    "        \n",
    "        # Compute BM25 values for each term in the document\n",
    "        for term, count in term_counts.items():\n",
    "            if term in term_to_index:\n",
    "                # Calculate BM25 term frequency component\n",
    "                tf_component = (count * (k1 + 1)) / (count + k1 * (1 - b + b * (doc_length / avgdl)))\n",
    "                \n",
    "                # Append to sparse matrix lists (row, column, data)\n",
    "                rows.append(doc_idx)\n",
    "                cols.append(term_to_index[term])\n",
    "                data.append(tf_component)\n",
    "    \n",
    "    # Create the sparse matrix (Compressed Sparse Row format)\n",
    "    bm25_matrix = csr_matrix((data, (rows, cols)), shape=(len(df), len(vocabulary)))\n",
    "    \n",
    "    return bm25_matrix, vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841eba18-0770-4eec-9b01-f3b40d3295a4",
   "metadata": {},
   "source": [
    "Now we can calculate the sparse BM25 matrix of each language as well as the corresponding vocabulary, for k1 equal to 1,8 as frequency saturation term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8034041e-1b09-4846-a97e-2eabe262922b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the bm25 sparse matrix for English\n",
    "avgdl_en = sum(doc_len_dict_en.values())/len(doc_len_dict_en)\n",
    "bm25_matrix_en, bm25_vocabulary_en = create_bm25_sparse_matrix(corpus_en, doc_len_dict_en, idf_dict_en, b=0.75, k1=1.8, avgdl=avgdl_en)\n",
    "\n",
    "# Save the bm25 matrix and vocabulary\n",
    "sp.save_npz('Data/bm25_matrix_en.npz', bm25_matrix_en)\n",
    "pd.to_pickle(bm25_vocabulary_en, 'Data/bm25_vocabulary_en.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8715a436-ac79-4f6d-98ce-a6b018fe7fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the bm25 sparse matrix for French\n",
    "avgdl_fr = sum(doc_len_dict_fr.values())/len(doc_len_dict_fr)\n",
    "bm25_matrix_fr, bm25_vocabulary_fr = create_bm25_sparse_matrix(corpus_fr, doc_len_dict_fr, idf_dict_fr, b=0.75, k1=1.8, avgdl=avgdl_fr)\n",
    "\n",
    "# Save the bm25 matrix and vocabulary\n",
    "sp.save_npz('Data/bm25_matrix_fr.npz', bm25_matrix_fr)\n",
    "pd.to_pickle(bm25_vocabulary_fr, 'Data/bm25_vocabulary_fr.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445f4790-e1b7-498a-be4c-98d05de70068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the bm25 sparse matrix for German\n",
    "avgdl_de = sum(doc_len_dict_de.values())/len(doc_len_dict_de)\n",
    "bm25_matrix_de, bm25_vocabulary_de = create_bm25_sparse_matrix(corpus_de, doc_len_dict_de, idf_dict_de, b=0.75, k1=1.8, avgdl=avgdl_de)\n",
    "\n",
    "# Save the bm25 matrix and vocabulary\n",
    "sp.save_npz('Data/bm25_matrix_de.npz', bm25_matrix_de)\n",
    "pd.to_pickle(bm25_vocabulary_de, 'Data/bm25_vocabulary_de.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc0e1e8-9fcf-4a9f-a829-78f737f85a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the bm25 sparse matrix for Spanish\n",
    "avgdl_es = sum(doc_len_dict_es.values())/len(doc_len_dict_es)\n",
    "bm25_matrix_es, bm25_vocabulary_es = create_bm25_sparse_matrix(corpus_es, doc_len_dict_es, idf_dict_es, b=0.75, k1=1.8, avgdl=avgdl_es)\n",
    "\n",
    "# Save the bm25 matrix and vocabulary\n",
    "sp.save_npz('Data/bm25_matrix_es.npz', bm25_matrix_es)\n",
    "pd.to_pickle(bm25_vocabulary_es, 'Data/bm25_vocabulary_es.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddb46e4-21cd-4b45-9b3a-f864597f365b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the bm25 sparse matrix for Italian\n",
    "avgdl_it = sum(doc_len_dict_it.values())/len(doc_len_dict_it)\n",
    "bm25_matrix_it, bm25_vocabulary_it = create_bm25_sparse_matrix(corpus_it, doc_len_dict_it, idf_dict_it, b=0.75, k1=1.8, avgdl=avgdl_it)\n",
    "\n",
    "# Save the bm25 matrix and vocabulary\n",
    "sp.save_npz('Data/bm25_matrix_it.npz', bm25_matrix_it)\n",
    "pd.to_pickle(bm25_vocabulary_it, 'Data/bm25_vocabulary_it.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1534577e-c78b-4274-94b6-58c7c60d0154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the bm25 sparse matrix for Arabic\n",
    "avgdl_ar = sum(doc_len_dict_ar.values())/len(doc_len_dict_ar)\n",
    "bm25_matrix_ar, bm25_vocabulary_ar = create_bm25_sparse_matrix(corpus_ar, doc_len_dict_ar, idf_dict_ar, b=0.75, k1=1.8, avgdl=avgdl_ar)\n",
    "\n",
    "# Save the bm25 matrix and vocabulary\n",
    "sp.save_npz('Data/bm25_matrix_ar.npz', bm25_matrix_ar)\n",
    "pd.to_pickle(bm25_vocabulary_ar, 'Data/bm25_vocabulary_ar.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a33a64-aa03-4aca-afea-b13e7693f563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the bm25 sparse matrix for Korean\n",
    "avgdl_ko = sum(doc_len_dict_ko.values())/len(doc_len_dict_ko)\n",
    "bm25_matrix_ko, bm25_vocabulary_ko = create_bm25_sparse_matrix(corpus_ko, doc_len_dict_ko, idf_dict_ko, b=0.75, k1=1.8, avgdl=avgdl_ko)\n",
    "\n",
    "# Save the bm25 matrix and vocabulary\n",
    "sp.save_npz('Data/bm25_matrix_ko.npz', bm25_matrix_ko)\n",
    "pd.to_pickle(bm25_vocabulary_ko, 'Data/bm25_vocabulary_ko.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7ae160-5ad2-42a3-b650-f27d03c022fd",
   "metadata": {},
   "source": [
    "The calculations we performed will serve as the basis for several critical tasks during document retrieval and similarity analysis in the next steps of our project."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
